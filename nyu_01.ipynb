{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0086adc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4930e+00,  6.2830e-01,  2.8281e-01, -4.3307e-01,  8.3658e-01,\n",
      "          -7.6857e-01, -1.4028e+00, -5.6412e-01,  9.7648e-01,  6.7527e-01,\n",
      "          -2.1581e-02, -1.2274e+00, -8.6623e-01,  1.3095e+00, -2.0787e-01,\n",
      "           8.2922e-01, -1.2210e+00,  1.6212e-01, -1.0874e+00,  1.5373e-01],\n",
      "         [ 1.2364e+00, -1.5682e+00, -4.8697e-01,  1.1749e+00, -2.0472e+00,\n",
      "          -4.5994e-01,  3.0243e-02, -1.6930e+00,  2.7412e-01, -6.0203e-01,\n",
      "          -9.5316e-01, -7.2329e-01,  5.4965e-01,  9.5734e-01,  3.0211e-01,\n",
      "          -2.8166e-01, -4.1844e-01, -4.9897e-01, -1.8961e-03,  9.9184e-01],\n",
      "         [ 1.2161e-02,  1.3097e+00,  1.7806e-01,  3.8917e-01, -1.3419e+00,\n",
      "          -3.3934e-01,  1.3978e-02,  9.0219e-01,  5.3105e-01, -1.8321e+00,\n",
      "           6.4292e-01,  3.7701e-01, -5.5923e-01, -2.7650e+00,  1.0684e+00,\n",
      "           9.5717e-01,  6.8846e-01, -5.8837e-01, -2.9877e-01, -1.2852e+00],\n",
      "         [ 1.5898e+00, -6.5865e-01, -1.3237e+00, -4.6971e-01,  5.3022e-01,\n",
      "          -3.4351e-01, -8.6519e-01, -2.0641e-01, -8.8449e-01, -1.2005e+00,\n",
      "          -7.4325e-01,  5.6444e-01,  2.5126e-02,  4.0712e-01, -3.2011e-01,\n",
      "          -4.4246e-01, -2.7306e-01, -5.5327e-03, -5.6462e-01,  2.6282e-01],\n",
      "         [ 4.6706e-01,  6.4413e-01,  9.1643e-01, -5.0362e-01, -3.4252e-01,\n",
      "           1.4853e+00,  9.7746e-02,  4.7260e-01,  2.2020e-01,  9.7891e-02,\n",
      "           1.3614e+00, -6.1220e-01, -1.1878e+00, -1.8071e-01,  2.2883e-01,\n",
      "          -8.3004e-01, -5.3781e-01, -8.1350e-02, -4.1780e-01,  4.0149e-01],\n",
      "         [ 1.3407e-02, -5.2832e-01,  2.9761e-01, -1.0464e+00, -2.4474e-01,\n",
      "           6.7426e-01,  8.2634e-01, -1.9009e-01,  3.2344e-01,  1.9431e+00,\n",
      "           1.5086e+00, -3.1425e-01, -1.8839e+00,  3.8964e-01,  2.6136e-01,\n",
      "          -8.3692e-01,  1.7089e-01, -5.2246e-01,  3.1617e-01, -6.2283e-01],\n",
      "         [ 9.0671e-01,  8.4983e-01,  5.5087e-01,  1.1537e+00,  1.8404e+00,\n",
      "           8.7821e-01, -6.4650e-01, -4.2476e-01, -2.1782e-01, -7.5056e-01,\n",
      "          -6.7670e-01, -2.3973e-01, -1.7807e+00, -1.7125e-01,  5.3155e-01,\n",
      "          -9.7952e-01, -8.2279e-01, -9.3769e-01,  7.5334e-01,  1.3128e+00],\n",
      "         [-5.8594e-01,  2.0200e+00,  1.3617e+00, -5.0408e-01, -1.0265e+00,\n",
      "           1.5648e+00,  1.2712e+00, -8.8811e-02,  2.4187e-01, -2.9588e-01,\n",
      "           1.0863e+00, -4.6982e-01,  1.8211e-02, -6.4892e-01,  8.1253e-01,\n",
      "          -8.9948e-01,  1.6144e+00,  1.9167e+00, -1.5028e+00,  9.3733e-01],\n",
      "         [-5.4396e-01, -3.3171e-01, -3.9620e-01, -5.3811e-01,  7.4260e-01,\n",
      "          -8.4963e-01, -1.4716e-01,  1.5891e+00, -7.1546e-01,  3.3164e-01,\n",
      "           3.9503e-01, -9.8561e-01,  7.7477e-01, -4.0126e-01,  2.9193e-01,\n",
      "           5.9983e-01,  1.0166e-01,  4.5964e-01,  4.5896e-01, -2.1073e+00],\n",
      "         [-1.1917e+00,  1.1117e+00, -2.3307e-01,  2.2753e-01, -7.2752e-01,\n",
      "           8.5813e-01,  1.3360e+00,  5.6612e-01, -1.7047e+00, -2.3056e+00,\n",
      "          -1.2695e+00,  9.2378e-01, -9.8105e-01, -5.5496e-01, -6.1876e-01,\n",
      "           1.7520e+00, -9.4248e-01, -1.1390e+00, -8.6004e-01,  7.2802e-01]],\n",
      "\n",
      "        [[ 7.0312e-02, -1.5497e+00,  1.0003e+00,  7.7894e-01, -1.7236e+00,\n",
      "          -1.0260e+00,  8.6875e-01, -7.6395e-01,  1.8773e+00, -1.7128e+00,\n",
      "          -2.3929e+00, -1.2375e+00,  8.1221e-01, -1.5102e+00, -1.7653e+00,\n",
      "           2.2170e-01, -4.3640e-01, -3.6651e-01, -2.3688e+00,  2.4641e-01],\n",
      "         [ 4.1716e-02,  8.4662e-01, -1.3640e+00, -8.4383e-01,  1.0077e+00,\n",
      "           4.0613e-01,  2.2667e-01, -6.5095e-01, -7.4895e-01,  6.7623e-01,\n",
      "           3.2000e-01,  1.9306e-01, -1.6052e+00,  8.7137e-01, -3.8305e-01,\n",
      "          -1.5183e+00, -1.1507e+00, -1.5449e+00, -5.0678e-01,  8.7562e-02],\n",
      "         [ 1.1044e+00,  1.4933e+00,  1.8442e-01, -5.0461e-01, -5.0993e-01,\n",
      "           2.6451e-01,  1.6186e+00, -6.4854e-01, -5.7602e-01,  3.7595e-01,\n",
      "          -1.3263e+00, -1.5168e+00, -1.5575e+00,  5.4376e-01,  2.0935e+00,\n",
      "           1.5930e+00, -1.4672e+00,  4.5732e-01,  1.7896e+00,  1.0734e+00],\n",
      "         [-2.3448e-01,  6.8136e-01,  7.2018e-01, -5.3739e-04, -8.1297e-01,\n",
      "           7.2763e-01, -1.5367e+00, -7.1536e-01, -6.8485e-01,  9.3888e-01,\n",
      "           2.6018e-02, -3.0776e-01, -1.7468e-01,  1.1514e+00, -6.0872e-01,\n",
      "           4.6557e-01,  9.6238e-01, -2.4169e+00,  8.7116e-01, -2.1257e-01],\n",
      "         [-6.9312e-01,  3.8113e+00,  1.7548e+00, -8.7425e-01,  1.0915e+00,\n",
      "           8.3539e-01,  1.3398e+00, -1.2159e+00, -9.4925e-01, -1.1439e+00,\n",
      "          -1.2753e+00,  4.8243e-01, -2.0700e+00,  5.9701e-01,  3.8034e-01,\n",
      "          -1.0162e+00,  1.4355e+00,  4.5932e-01, -1.0259e+00,  9.3432e-01],\n",
      "         [-6.8178e-01, -6.4593e-01, -9.0081e-01,  1.1043e+00, -8.9194e-03,\n",
      "          -3.9868e-01,  1.3644e+00,  1.3765e+00,  9.0633e-02, -9.2311e-02,\n",
      "           2.8808e-01,  3.1895e-01,  3.7216e-01,  1.8560e+00, -3.9362e-01,\n",
      "          -3.0592e-01, -4.1865e-02,  6.0387e-01, -1.9723e-01, -2.0333e+00],\n",
      "         [ 2.0270e+00, -1.0920e+00, -3.1043e-01, -1.0029e-01,  1.3491e+00,\n",
      "          -5.1238e-01,  1.9709e+00, -1.3143e+00,  7.0208e-01,  1.6316e+00,\n",
      "          -2.0220e+00,  1.0396e+00, -6.4932e-02, -1.3336e+00, -1.9954e-01,\n",
      "           5.1954e-01,  7.5562e-01,  4.5803e-01, -1.2548e+00,  2.1065e+00],\n",
      "         [-5.6753e-01, -4.6157e-01,  2.9409e-02,  1.9765e-01,  5.6116e-01,\n",
      "          -3.8100e-01,  4.8781e-01,  1.6461e+00, -4.6198e-01, -1.2793e+00,\n",
      "          -3.1063e-01,  8.8411e-01, -1.3883e+00, -6.2594e-01,  7.2204e-02,\n",
      "          -1.7452e+00, -4.9761e-01, -7.3281e-01,  2.6381e-01, -2.0704e-01],\n",
      "         [-6.1847e-01, -1.6714e+00,  7.1385e-01, -1.1100e+00,  9.6261e-02,\n",
      "           1.1248e+00,  7.5215e-01, -5.4175e-01, -5.5222e-01,  3.8844e-01,\n",
      "           2.4833e-01,  7.9840e-01, -1.5259e+00,  7.3865e-01, -1.2903e+00,\n",
      "          -9.0679e-03,  1.7860e-01, -3.1495e-01,  2.2013e+00,  7.2826e-01],\n",
      "         [-1.3013e+00,  1.8977e+00, -2.2533e-01,  1.2704e+00, -2.9791e-01,\n",
      "          -6.6081e-01,  1.6075e-01,  5.1795e-01,  1.7437e+00, -2.8874e-01,\n",
      "           7.7824e-01,  8.1696e-05, -3.2918e-01, -4.6568e-01,  6.6806e-01,\n",
      "          -6.2493e-01, -1.4146e+00,  1.2615e+00, -2.2680e-01, -6.8252e-01]],\n",
      "\n",
      "        [[ 1.4720e+00, -7.4656e-02,  7.2159e-01, -1.4249e-01, -1.6324e+00,\n",
      "           2.2886e+00, -5.8746e-01,  3.1581e-01, -7.8719e-01, -1.2036e+00,\n",
      "          -1.3460e+00,  2.0011e+00, -2.4275e-01,  1.7225e+00, -2.6402e-02,\n",
      "          -2.8263e-02,  1.2495e+00,  1.2239e+00, -1.4438e+00, -2.1349e-01],\n",
      "         [ 9.4540e-01,  7.6555e-02,  2.8159e-01,  1.4672e+00, -7.7594e-01,\n",
      "           2.2310e-01, -1.2616e+00,  3.8660e-01, -1.4470e+00, -1.1440e+00,\n",
      "          -8.5035e-01, -5.9022e-01, -4.0602e-01, -9.1696e-01,  2.2535e-01,\n",
      "          -6.5283e-01,  2.3500e-01, -2.2898e+00,  4.0635e-01, -7.7216e-01],\n",
      "         [-3.3521e-01, -7.4778e-01, -4.4606e-01, -3.8591e-01, -6.1605e-01,\n",
      "           1.4168e+00,  1.3739e+00,  9.2681e-01, -1.0856e+00, -3.9965e-01,\n",
      "           2.4507e-01, -5.7878e-01, -7.2255e-02,  9.4190e-02, -2.6090e-01,\n",
      "          -1.5652e+00,  1.8097e-01,  1.9672e-01,  2.6056e-01, -3.8291e-01],\n",
      "         [ 8.5357e-01, -1.0454e+00, -5.7996e-01, -2.8478e-02,  6.8866e-01,\n",
      "          -1.8874e+00,  8.9024e-01, -8.4921e-01, -2.1455e+00, -1.5845e+00,\n",
      "           6.5945e-02,  6.1503e-01, -5.7600e-01,  5.0367e-02, -1.0580e+00,\n",
      "          -2.7745e-01, -1.6193e-01, -5.7684e-02, -3.8829e-01, -1.2258e+00],\n",
      "         [-7.6615e-02,  7.9526e-01, -1.0292e-01, -3.8541e-01,  1.3219e+00,\n",
      "          -1.6951e-02, -4.9886e-01,  2.1896e-02,  1.1486e+00, -3.0262e-01,\n",
      "           2.5819e-01,  4.2760e-01,  1.6535e+00,  8.9429e-01, -3.5839e-01,\n",
      "          -7.4597e-01,  3.3060e-01, -5.3515e-02,  1.1316e+00,  9.6884e-03],\n",
      "         [ 8.4127e-01, -4.9544e-01, -8.5686e-01,  1.0988e+00,  2.8944e-01,\n",
      "          -3.8792e-01, -3.1716e-01,  8.4587e-01, -9.2226e-01, -2.9518e-02,\n",
      "          -2.2994e+00, -2.0327e+00,  6.6241e-01, -7.9106e-01, -1.7596e+00,\n",
      "          -1.3623e+00,  1.3027e+00, -1.3124e+00,  4.0975e-01,  1.7018e+00],\n",
      "         [ 5.8847e-01, -6.7952e-02, -1.9664e+00, -5.8970e-01,  1.3212e-01,\n",
      "           2.4382e-01, -7.5922e-01, -2.0105e+00, -5.7700e-01, -2.2924e+00,\n",
      "          -2.3956e+00, -4.0614e-01, -7.8713e-02,  1.8984e+00,  3.7394e-01,\n",
      "           6.4796e-01,  1.6467e+00,  8.8157e-01,  9.9305e-01, -7.8841e-01],\n",
      "         [-3.2817e-01,  1.0690e+00, -1.5228e+00, -5.9967e-01, -7.8177e-02,\n",
      "          -9.1694e-02, -9.1059e-01,  4.9812e-01, -1.2287e-01,  3.2101e-02,\n",
      "           1.0438e+00, -3.3130e-01,  1.8170e+00, -9.3625e-01,  2.5609e-01,\n",
      "          -6.4176e-01,  5.4581e-01, -2.2422e+00,  2.3600e-01, -1.8304e+00],\n",
      "         [-6.9287e-01, -2.8565e-01, -1.3176e-01, -5.3484e-01,  8.5215e-01,\n",
      "           1.7823e+00,  1.9711e-02,  1.5868e+00, -1.2216e+00, -2.1376e-01,\n",
      "           7.6522e-01, -2.2113e-01, -1.3101e+00,  1.0135e-01, -2.0103e-01,\n",
      "           3.1707e-01,  1.9018e-01, -4.2704e-01,  6.1712e-01,  2.6331e-01],\n",
      "         [ 1.2823e+00,  8.4356e-01, -5.4960e-01, -7.5631e-01, -1.9083e-02,\n",
      "          -3.1153e-01,  3.0008e-01, -2.3287e+00, -2.7038e-01,  1.6054e+00,\n",
      "          -2.6612e-01,  6.3923e-01,  1.6700e+00,  9.4208e-03,  1.3152e+00,\n",
      "           8.5311e-03,  3.1830e-01,  1.9585e+00, -1.2563e+00, -9.6022e-01]]])\n",
      "tensor([ 5.6431e-05, -1.1604e-01, -8.7227e-02, -2.5422e-01,  8.6331e-02,\n",
      "         1.1000e-01,  8.0743e-02, -1.2627e-01, -2.3864e-01,  1.2056e-01],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "image = torch.randn(3, 10, 20)\n",
    "d0 = image.nelement()\n",
    "\n",
    "class mynet(nn.Module):\n",
    "    def __init__(self, d0, d1, d2, d3):\n",
    "        super().__init__()\n",
    "        self.m0 = nn.Linear(d0, d1)\n",
    "        self.m1 = nn.Linear(d1, d2)\n",
    "        self.m2 = nn.Linear(d2, d3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z0 = x.view(-1)\n",
    "        s1 = self.m0(z0)\n",
    "        z1 = torch.relu(s1)\n",
    "        s2 = self.m1(z1)\n",
    "        z2 = torch.relu(s2)\n",
    "        s3 = self.m2(z2)\n",
    "        return s3\n",
    "\n",
    "model = mynet(d0, 60, 40, 10)\n",
    "out = model(image)\n",
    "print(image)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57af567",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd8151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10859f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gattor\n",
    "gattor_f = nn.Linear(3, 2)\n",
    "gattor_sm = nn.Softmax(2)\n",
    "# nn_1\n",
    "exp_1_f = nn.Linear(2, 4)\n",
    "exp_1__relu = nn.ReLU()\n",
    "exp_1_f2 = nn.Linear(4, 1)\n",
    "exp_1__relu2 = nn.ReLU()\n",
    "# nn_2\n",
    "exp_2_f = nn.Linear(2, 4)\n",
    "exp_2__relu = nn.ReLU()\n",
    "exp_2_f2 = nn.Linear(4, 1)\n",
    "exp_2__relu2 = nn.ReLU()\n",
    "\n",
    "gattor = nn.Sequential(gattor_f, gattor_sm)\n",
    "net_1 = nn.Sequential(exp_1_f, exp_1__relu, exp_1_f2, exp_1__relu2)\n",
    "net_2 = nn.Sequential(exp_2_f, exp_2__relu, exp_2_f2, exp_2__relu2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1bed4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1,2,3], [7, -4, 28], [4, 7, 9.6], [2, 6, 9.5], [32, 7, 3]], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4300eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m----> 2\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[43mgattor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(decision)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gymnasium/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gymnasium/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gymnasium/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gymnasium/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gymnasium/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gymnasium/lib/python3.11/site-packages/torch/nn/modules/activation.py:1667\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gymnasium/lib/python3.11/site-packages/torch/nn/functional.py:2140\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2138\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   2139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2140\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2142\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "for pair in data:\n",
    "    decision = gattor(torch.Tensor(pair).shape(1, 3))\n",
    "    print(decision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b34b7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583a208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymnasium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
