{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b18dc8",
   "metadata": {},
   "source": [
    "## Deep Learning with pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df1d7c1",
   "metadata": {},
   "source": [
    "### Basics of torch and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cd0b4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3), tensor([3]), torch.Size([]), torch.Size([1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a = torch.FloatTensor(1, 3, 2)\n",
    "a\n",
    "torch.zeros(2, 6)\n",
    "a.zero_()\n",
    "b = torch.FloatTensor([[1, 2, 3], [3, 2, 1]])\n",
    "b\n",
    "c = np.zeros((3, 3), dtype=np.int32)\n",
    "d = torch.tensor((c))\n",
    "c, d, np.concatenate((c, d))\n",
    "## no dim vs 1 dim\n",
    "no_dim = torch.tensor(3)\n",
    "one_dim = torch.tensor([3]) # or\n",
    "no_dim, one_dim, no_dim.shape, one_dim.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f03a6",
   "metadata": {},
   "source": [
    "### Computation device types; cpu vs gpu vs mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f96f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 3.]), tensor([2., 3.], device='mps:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([2, 3])\n",
    "# ca = a.to('cuda') # this mac doesn't have cuda but what could have been :)\n",
    "ma = a.to('mps')\n",
    "a, ma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018afe2",
   "metadata": {},
   "source": [
    "### Tensors with gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb8d8f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7d/zb8kng_12yz5ccnt2sy4v0mr0000gn/T/ipykernel_21205/2809331367.py:7: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  v1.grad, v2.grad, v_sum.grad, v_res.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.tensor([2, 3.], requires_grad=True)\n",
    "v2 = torch.tensor([1., 0.])\n",
    "v_sum = v1 + v2\n",
    "v_sum\n",
    "v_res = (v_sum*2).sum()\n",
    "v_res\n",
    "v1.grad, v2.grad, v_sum.grad, v_res.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3020e",
   "metadata": {},
   "source": [
    "## Neural Networks in Pytorch (NNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf7fb5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=20, bias=False)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.3, inplace=False)\n",
       "  (7): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "l = nn.Linear(2, 5)\n",
    "v = torch.FloatTensor([[1, 2]])\n",
    "l(v)\n",
    "s = nn.Sequential(\n",
    "    nn.Linear(2, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 20, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Softmax(dim=1),\n",
    ")\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00fe23",
   "metadata": {},
   "source": [
    "## nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e117e30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2348, 0.1174, 0.1445, 0.2516, 0.2516],\n",
       "        [0.1983, 0.0822, 0.1408, 0.2401, 0.3386],\n",
       "        [0.1974, 0.0987, 0.1215, 0.2115, 0.3708],\n",
       "        [0.1740, 0.1946, 0.1236, 0.2107, 0.2972]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OurModule(nn.Module):\n",
    "    def __init__(self, num_inputs, num_classes, dropout_prob=0.3):\n",
    "        super(OurModule, self).__init__()\n",
    "        self.pipe = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, num_classes),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)\n",
    "\n",
    "model = OurModule(num_inputs=2, num_classes=5)\n",
    "model(torch.FloatTensor([[4, 9], [5, 8], [4, 9], [5, 8]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59862b1",
   "metadata": {},
   "source": [
    "### Loss Functions and Optimizers\n",
    "\n",
    "#### a common blueprint for a training loop\n",
    "\n",
    "##### for batch_x, batch_y in iterate_batches(data, batch_size=N):\n",
    "##### >>>>batch_x_t = torch.tensor(batch_x)\n",
    "##### >>>>batch_y_t = torch.tensor(batch_y)\n",
    "##### >>>>out_t = model(batch_x_t)\n",
    "##### >>>>loss_t = loss_function(batch_y_t, out_t)\n",
    "##### >>>>loss_t.backward()\n",
    "##### >>>>optimizer.step()\n",
    "##### >>>>optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fac068",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef08b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    writer = SummaryWriter()\n",
    "    funcs = {\"sin\": math.sin, \"cos\": math.cos, \"tan\": math.tan}\n",
    "\n",
    "    for angle in range(-360, 360):\n",
    "        angle_rad = math.pi * angle / 180\n",
    "        for name, fun in funcs.items():\n",
    "            val = fun(angle_rad)\n",
    "            writer.add_scalar(name, val, angle)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d63deb",
   "metadata": {},
   "source": [
    "## GANs\n",
    "\n",
    "#### This code in part_02_project.py generates atari-like images using a generator and a discriminator nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60d270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymnasium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
